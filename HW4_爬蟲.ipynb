{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmrGVuYDjO0pZ4attdzHQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alisonnnnn88/programming_language/blob/main/HW4_%E7%88%AC%E8%9F%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio google-generativeai --upgrade\n",
        "!pip install plotly\n",
        "!pip install gspread gspread_dataframe pandas beautifulsoup4 gradio python-dateutil requests jieba scikit-learn --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jceVXTTV2CDV",
        "outputId": "282fa964-7f51-4b54-9d1f-db3e8020f73a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.3.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.14.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (0.42.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import pandas as pd\n",
        "import io\n",
        "import tempfile\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import uuid\n",
        "from dateutil.tz import gettz\n",
        "import jieba\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "EnLdX0JB2HBv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Google Sheets ---\n",
        "# Google èªè­‰ (Colab å°ˆç”¨)\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# è¨­å®š Google Sheets URL å’Œå·¥ä½œè¡¨\n",
        "SPREADSHEET_URL = \"https://docs.google.com/spreadsheets/d/1h75idXVO6GMosL5bPUF-G76MqxOziHu1tJieRtpdkP4/edit?usp=sharing\"\n",
        "sh = gc.open_by_url(SPREADSHEET_URL)\n",
        "\n",
        "# å·¥ä½œè¡¨è¨­å®š\n",
        "user_ws = sh.worksheet(\"ä½¿ç”¨è€…è³‡æ–™è¡¨\")\n",
        "record_ws = sh.worksheet(\"äº¤æ˜“ç´€éŒ„è¡¨\")\n",
        "ai_ws = sh.worksheet(\"AIå»ºè­°ç´€éŒ„\")\n",
        "\n",
        "CLIPS_HEADER = [\"clip_id\",\"text\",\"href\",\"fetched_at\"]\n",
        "PTT_HEADER = [\"post_id\",\"title\",\"url\",\"date\",\"author\",\"nrec\",\"created_at\",\"fetched_at\",\"content\"]\n",
        "TERMS_HEADER = [\"term\",\"freq\",\"df_count\",\"tfidf_mean\",\"examples\"]\n",
        "\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    try:\n",
        "        ws = sh.worksheet(title)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "        ws.update([header])\n",
        "    data = ws.get_all_values()\n",
        "    if not data or (data and data[0] != header):\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "    return ws\n",
        "\n",
        "ws_clips = ensure_worksheet(sh, \"web_clips\", CLIPS_HEADER)\n",
        "ws_ptt_posts = ensure_worksheet(sh, \"ptt_creditcard_posts\", PTT_HEADER)\n",
        "ws_ptt_terms = ensure_worksheet(sh, \"ptt_creditcard_terms\", TERMS_HEADER)\n",
        "\n",
        "\n",
        "# è¨­å®šç™»å…¥ç³»çµ±\n",
        "current_user = None\n",
        "\n",
        "# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---\n",
        "\n",
        "def handle_register(username, password):\n",
        "    users = [str(u).strip() for u in user_ws.col_values(1) if u is not None]\n",
        "    if username in users:\n",
        "        return \"âš ï¸ å¸³è™Ÿå·²å­˜åœ¨\"\n",
        "    else:\n",
        "        user_ws.append_row([username, password])\n",
        "        return f\"âœ… è¨»å†ŠæˆåŠŸï¼Œè«‹ç™»å…¥\"\n",
        "\n",
        "def handle_login(username, password):\n",
        "    global current_user\n",
        "    users_dict = {str(row['ä½¿ç”¨è€…åç¨±']).strip(): str(row['å¯†ç¢¼']).strip()\n",
        "                  for row in user_ws.get_all_records() if row['ä½¿ç”¨è€…åç¨±'] is not None}\n",
        "\n",
        "    if username in users_dict and users_dict[username] == password:\n",
        "        current_user = username\n",
        "        return f\"âœ… ç™»å…¥æˆåŠŸï¼Œæ­¡è¿ {username}ï¼\\nè«‹é¸æ“‡æ“ä½œ\"\n",
        "    else:\n",
        "        return \"âŒ å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤\"\n",
        "\n",
        "def handle_income(income):\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥\"\n",
        "    if int(income) <= 0:\n",
        "        return \"âŒ è¼¸å…¥é‡‘é¡éœ€å¤§æ–¼0ï¼Œè«‹é‡æ–°è¼¸å…¥\"\n",
        "    tz = pytz.timezone(\"Asia/Taipei\")\n",
        "    now = datetime.now(tz)\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user] if not df.empty else pd.DataFrame()\n",
        "    previous_balance = float(user_df.iloc[-1][\"é¤˜é¡\"]) if not user_df.empty else 0.0\n",
        "    new_balance = previous_balance + int(income)\n",
        "    record_ws.append_row([current_user, now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M:%S\"),\n",
        "                          int(income), 0, 0, new_balance])\n",
        "    return f\"âœ… å·²æ–°å¢å­˜æ¬¾é‡‘é¡ï¼š{income} å…ƒ\"\n",
        "\n",
        "def handle_expense(expense):\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥\"\n",
        "    amount = int(expense)\n",
        "    if amount <= 0:\n",
        "        return \"âŒ è¼¸å…¥é‡‘é¡éœ€å¤§æ–¼0ï¼Œè«‹é‡æ–°è¼¸å…¥\"\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user] if not df.empty else pd.DataFrame()\n",
        "    balance = float(user_df.iloc[-1][\"é¤˜é¡\"]) if not user_df.empty else 0.0\n",
        "    if amount > balance:\n",
        "        return \"âŒ é¤˜é¡ä¸è¶³ï¼\"\n",
        "    else:\n",
        "        tz = pytz.timezone(\"Asia/Taipei\")\n",
        "        now = datetime.now(tz)\n",
        "        new_balance = balance - amount\n",
        "        record_ws.append_row([current_user, now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M:%S\"),\n",
        "                              0, amount, 0, new_balance])\n",
        "        return f\"âœ… å·²æ–°å¢ææ¬¾é‡‘é¡ï¼š{amount} å…ƒ\"\n",
        "\n",
        "def handle_balance():\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥\"\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user] if not df.empty else pd.DataFrame()\n",
        "    balance = int(float(user_df.iloc[-1][\"é¤˜é¡\"])) if not user_df.empty else 0\n",
        "    return f\"ğŸ’° æ‚¨ç›®å‰çš„é¤˜é¡ç‚ºï¼š{balance} å…ƒ\"\n",
        "\n",
        "def handle_transfer(target_user, amount):\n",
        "    global current_user\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥\"\n",
        "\n",
        "    # é‡‘é¡æª¢æŸ¥\n",
        "    amount = int(amount)\n",
        "    if amount <= 0:\n",
        "        return \"âŒ è½‰å¸³é‡‘é¡éœ€å¤§æ–¼0ï¼Œè«‹é‡æ–°è¼¸å…¥\"\n",
        "\n",
        "    # ç¢ºèªç›®æ¨™å¸³è™Ÿå­˜åœ¨\n",
        "    users = [str(u).strip() for u in user_ws.col_values(1) if u is not None]\n",
        "    if target_user not in users:\n",
        "        return \"âŒ ç›®æ¨™å¸³è™Ÿä¸å­˜åœ¨ï¼Œè«‹ç¢ºèªå¸³è™Ÿæ˜¯å¦æ­£ç¢º\"\n",
        "\n",
        "    # å–å‡ºç›®å‰ä½¿ç”¨è€…é¤˜é¡\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user] if not df.empty else pd.DataFrame()\n",
        "    balance = float(user_df.iloc[-1][\"é¤˜é¡\"]) if not user_df.empty else 0.0\n",
        "\n",
        "    if amount > balance:\n",
        "        return \"âŒ é¤˜é¡ä¸è¶³ï¼Œç„¡æ³•è½‰å¸³\"\n",
        "\n",
        "    # æ™‚é–“æˆ³è¨˜\n",
        "    tz = pytz.timezone(\"Asia/Taipei\")\n",
        "    now = datetime.now(tz)\n",
        "\n",
        "    # æ›´æ–°è½‰å‡ºè€…é¤˜é¡\n",
        "    new_balance_sender = balance - amount\n",
        "    record_ws.append_row([current_user, now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M:%S\"),\n",
        "                          0, 0, amount, new_balance_sender])  # ğŸ‘ˆ å­˜æ¬¾=0, ææ¬¾=0, è½‰å¸³=é‡‘é¡\n",
        "\n",
        "    # æ›´æ–°æ”¶æ¬¾è€…é¤˜é¡\n",
        "    target_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == target_user] if not df.empty else pd.DataFrame()\n",
        "    target_balance = float(target_df.iloc[-1][\"é¤˜é¡\"]) if not target_df.empty else 0.0\n",
        "    new_balance_receiver = target_balance + amount\n",
        "    record_ws.append_row([target_user, now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M:%S\"),\n",
        "                          amount, 0, 0, new_balance_receiver])  # ğŸ‘ˆ å­˜æ¬¾=é‡‘é¡, å…¶ä»–=0\n",
        "\n",
        "    return f\"âœ… è½‰å¸³æˆåŠŸï¼æ‚¨å·²è½‰å‡º {amount} å…ƒçµ¦ {target_user}\\nğŸ’° æ‚¨çš„æ–°é¤˜é¡ç‚ºï¼š{int(new_balance_sender)} å…ƒ\"\n",
        "\n",
        "def handle_clear():\n",
        "    global current_user\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥\"\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "    new_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] != current_user] if not df.empty else pd.DataFrame()\n",
        "    record_ws.clear()\n",
        "    record_ws.append_row([\"ä½¿ç”¨è€…åç¨±\", \"æ—¥æœŸ\", \"æ™‚é–“\", \"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\", \"é¤˜é¡\"])\n",
        "    for row in new_df.values.tolist():\n",
        "        record_ws.append_row(row)\n",
        "    return \"ğŸ—‘ï¸ å·²æ¸…é™¤æ‚¨çš„æ‰€æœ‰ç´€éŒ„\"\n",
        "\n",
        "def handle_logout():\n",
        "    global current_user\n",
        "    current_user = None\n",
        "    return \"ğŸ‘‹ å·²ç™»å‡ºï¼è«‹é‡æ–°ç™»å…¥\"\n",
        "\n",
        "def handle_records_with_date(start_date, end_date):\n",
        "    \"\"\"ä¾ç…§æ™‚é–“ç¯„åœç¯©é¸ç›®å‰ä½¿ç”¨è€…çš„äº¤æ˜“ç´€éŒ„\"\"\"\n",
        "    if current_user is None:\n",
        "        return pd.DataFrame([[\"âŒ è«‹å…ˆç™»å…¥\"]], columns=[\"è¨Šæ¯\"])\n",
        "\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if df.empty:\n",
        "        return pd.DataFrame([[\"å°šç„¡ç´€éŒ„\"]], columns=[\"è¨Šæ¯\"])\n",
        "\n",
        "    df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user]\n",
        "\n",
        "    if user_df.empty:\n",
        "        return pd.DataFrame([[\"å°šç„¡ç´€éŒ„\"]], columns=[\"è¨Šæ¯\"])\n",
        "\n",
        "    # åˆä½µæ—¥æœŸèˆ‡æ™‚é–“\n",
        "    user_df[\"æ—¥æœŸæ™‚é–“\"] = pd.to_datetime(\n",
        "        user_df[\"æ—¥æœŸ\"].astype(str).str.strip() + \" \" + user_df[\"æ™‚é–“\"].astype(str).str.strip(),\n",
        "        errors=\"coerce\"\n",
        "    )\n",
        "\n",
        "    # ç¯©é¸æ—¥æœŸç¯„åœ\n",
        "    if start_date:\n",
        "        try:\n",
        "            start = pd.to_datetime(start_date)\n",
        "            user_df = user_df[user_df[\"æ—¥æœŸæ™‚é–“\"] >= start]\n",
        "        except:\n",
        "            pass\n",
        "    if end_date:\n",
        "        try:\n",
        "            end = pd.to_datetime(end_date)\n",
        "            user_df = user_df[user_df[\"æ—¥æœŸæ™‚é–“\"] <= end]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if user_df.empty:\n",
        "        return pd.DataFrame([[\"âš ï¸ æ­¤æ—¥æœŸå€é–“ç„¡äº¤æ˜“ç´€éŒ„\"]], columns=[\"è¨Šæ¯\"])\n",
        "\n",
        "    return user_df[[\"æ—¥æœŸ\", \"æ™‚é–“\", \"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\", \"é¤˜é¡\"]]\n",
        "\n",
        "\n",
        "def handle_export_csv():\n",
        "    \"\"\"åŒ¯å‡ºç›®å‰ä½¿ç”¨è€…çš„äº¤æ˜“ç´€éŒ„æˆ CSV æª”æ¡ˆ\"\"\"\n",
        "    if current_user is None:\n",
        "        return None, \"âŒ è«‹å…ˆç™»å…¥æ‰èƒ½åŒ¯å‡ºç´€éŒ„ã€‚\"\n",
        "\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if not df.empty:\n",
        "        df.columns = df.columns.str.strip()\n",
        "        user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user]\n",
        "    else:\n",
        "        user_df = pd.DataFrame()\n",
        "\n",
        "    if user_df.empty:\n",
        "        return None, \"ğŸ“ å°šç„¡å¯åŒ¯å‡ºçš„ç´€éŒ„ã€‚\"\n",
        "\n",
        "    # å»ºç«‹æš«å­˜æª”\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\", mode=\"w\", encoding=\"utf-8-sig\") as tmpfile:\n",
        "        user_df.to_csv(tmpfile.name, index=False, encoding=\"utf-8-sig\")\n",
        "        tmp_path = tmpfile.name\n",
        "\n",
        "    return tmp_path, f\"âœ… å·²åŒ¯å‡º {len(user_df)} ç­†ç´€éŒ„ï¼\"\n",
        "\n",
        "def handle_import_csv(file):\n",
        "    \"\"\"å¾ä¸Šå‚³çš„ CSV æª”æ–°å¢ç´€éŒ„åˆ°è©¦ç®—è¡¨\"\"\"\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥æ‰èƒ½åŒ¯å…¥ç´€éŒ„ã€‚\"\n",
        "    if file is None:\n",
        "        return \"âš ï¸ è«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆã€‚\"\n",
        "\n",
        "    try:\n",
        "        df_new = pd.read_csv(file.name)\n",
        "\n",
        "        # ç¢ºä¿æ¬„ä½å®Œæ•´\n",
        "        required_cols = {\"æ—¥æœŸ\", \"æ™‚é–“\", \"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\", \"é¤˜é¡\"}\n",
        "        if not required_cols.issubset(df_new.columns):\n",
        "            return \"âš ï¸ CSV æ¬„ä½éŒ¯èª¤ï¼Œè«‹ç¢ºèªåŒ…å«ã€Œæ—¥æœŸã€æ™‚é–“ã€å­˜æ¬¾ã€ææ¬¾ã€è½‰å¸³ã€é¤˜é¡ã€\"\n",
        "\n",
        "        # è£œä¸Šä½¿ç”¨è€…åç¨±æ¬„ä½\n",
        "        df_new[\"ä½¿ç”¨è€…åç¨±\"] = current_user\n",
        "\n",
        "        # å°‡ç©ºå€¼è£œç‚º 0ï¼Œä¸¦ç¢ºä¿æ•¸å€¼å®‰å…¨\n",
        "        for col in [\"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\", \"é¤˜é¡\"]:\n",
        "            df_new[col] = pd.to_numeric(df_new[col], errors=\"coerce\").fillna(0)\n",
        "\n",
        "        # å¯«å…¥è©¦ç®—è¡¨ï¼ˆé€åˆ—è™•ç†ï¼Œé¿å… JSON ä¸åˆè¦ï¼‰\n",
        "        for _, row in df_new.iterrows():\n",
        "            record_ws.append_row([\n",
        "                str(row[\"ä½¿ç”¨è€…åç¨±\"]),\n",
        "                str(row[\"æ—¥æœŸ\"]),\n",
        "                str(row[\"æ™‚é–“\"]),\n",
        "                float(row[\"å­˜æ¬¾\"]),\n",
        "                float(row[\"ææ¬¾\"]),\n",
        "                float(row[\"è½‰å¸³\"]),\n",
        "                float(row[\"é¤˜é¡\"])\n",
        "            ], value_input_option=\"USER_ENTERED\")\n",
        "\n",
        "        return f\"âœ… å·²æˆåŠŸåŒ¯å…¥ {len(df_new)} ç­†ç´€éŒ„ã€‚\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"âŒ åŒ¯å…¥å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "\n",
        "def handle_visualization_with_date(start_date, end_date):\n",
        "    \"\"\"æ ¹æ“šæ™‚é–“ç¯„åœè¦–è¦ºåŒ–ç›®å‰ä½¿ç”¨è€…çš„äº¤æ˜“ç´€éŒ„ (ä½¿ç”¨ Seaborn)\"\"\"\n",
        "    if current_user is None:\n",
        "        return \"âŒ è«‹å…ˆç™»å…¥æ‰èƒ½æŸ¥çœ‹çµ±è¨ˆåœ–è¡¨ã€‚\", None, None, None\n",
        "\n",
        "    # å–å¾—ç´€éŒ„\n",
        "    df = pd.DataFrame(record_ws.get_all_records())\n",
        "    if df.empty:\n",
        "        return \"ğŸ“ å°šç„¡äº¤æ˜“ç´€éŒ„ã€‚\", None, None, None\n",
        "\n",
        "    df.columns = df.columns.str.strip()\n",
        "    user_df = df[df[\"ä½¿ç”¨è€…åç¨±\"] == current_user]\n",
        "    if user_df.empty:\n",
        "        return \"ğŸ“ å°šç„¡æ‚¨çš„äº¤æ˜“ç´€éŒ„ã€‚\", None, None, None\n",
        "\n",
        "    # å°‡æ—¥æœŸèˆ‡æ™‚é–“åˆä½µæˆ datetime\n",
        "    user_df[\"æ—¥æœŸæ™‚é–“\"] = pd.to_datetime(\n",
        "        user_df[\"æ—¥æœŸ\"].astype(str) + \" \" + user_df[\"æ™‚é–“\"].astype(str),\n",
        "        errors=\"coerce\"\n",
        "    )\n",
        "\n",
        "    # ç¯©é¸æ—¥æœŸç¯„åœ\n",
        "    if start_date:\n",
        "        try:\n",
        "            start = pd.to_datetime(start_date)\n",
        "            user_df = user_df[user_df[\"æ—¥æœŸæ™‚é–“\"] >= start]\n",
        "        except:\n",
        "            pass\n",
        "    if end_date:\n",
        "        try:\n",
        "            end = pd.to_datetime(end_date)\n",
        "            user_df = user_df[user_df[\"æ—¥æœŸæ™‚é–“\"] <= end]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if user_df.empty:\n",
        "        return \"ğŸ“… æ­¤æ—¥æœŸå€é–“å…§ç„¡äº¤æ˜“ç´€éŒ„ã€‚\", None, None, None\n",
        "\n",
        "    # ====== ä¸­æ–‡å­—é«”è¨­å®š ======\n",
        "    plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "    # ====== ç”Ÿæˆé¤˜é¡è®ŠåŒ–æŠ˜ç·šåœ– ======\n",
        "    fig1, ax1 = plt.subplots(figsize=(10,5))\n",
        "    sns.lineplot(data=user_df, x='æ—¥æœŸæ™‚é–“', y='é¤˜é¡', marker='o', ax=ax1)\n",
        "    ax1.set_title(\"é¤˜é¡è®ŠåŒ–åœ–\")\n",
        "    ax1.set_xlabel(\"æ—¥æœŸ\")\n",
        "    ax1.set_ylabel(\"é¤˜é¡ (å…ƒ)\")\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # ====== ç”Ÿæˆäº¤æ˜“è¶¨å‹¢æ¢å½¢åœ– ======\n",
        "    user_melt = user_df.melt(id_vars=['æ—¥æœŸæ™‚é–“'], value_vars=['å­˜æ¬¾','ææ¬¾','è½‰å¸³'],\n",
        "                             var_name='äº¤æ˜“é¡å‹', value_name='é‡‘é¡')\n",
        "    # ææ¬¾å’Œè½‰å¸³é¡¯ç¤ºè² å€¼\n",
        "    user_melt.loc[user_melt['äº¤æ˜“é¡å‹'].isin(['ææ¬¾','è½‰å¸³']), 'é‡‘é¡'] *= -1\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(10,5))\n",
        "    sns.barplot(data=user_melt, x='æ—¥æœŸæ™‚é–“', y='é‡‘é¡', hue='äº¤æ˜“é¡å‹', ax=ax2)\n",
        "    ax2.set_title(\"äº¤æ˜“è¶¨å‹¢åœ–\")\n",
        "    ax2.set_xlabel(\"æ—¥æœŸ\")\n",
        "    ax2.set_ylabel(\"é‡‘é¡ (å…ƒ)\")\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    ax2.legend(title=\"äº¤æ˜“é¡å‹\")\n",
        "\n",
        "    # ====== ç”Ÿæˆäº¤æ˜“æ¯”ä¾‹åœ“é¤…åœ– ======\n",
        "    total_income = user_df[\"å­˜æ¬¾\"].sum()\n",
        "    total_expense = user_df[\"ææ¬¾\"].sum()\n",
        "    total_transfer = user_df[\"è½‰å¸³\"].sum()\n",
        "    labels = [\"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\"]\n",
        "    sizes = [total_income, total_expense, total_transfer]\n",
        "\n",
        "    fig3, ax3 = plt.subplots(figsize=(6,6))\n",
        "    ax3.pie(sizes, labels=labels, autopct=\"%1.1f%%\", startangle=90)\n",
        "    ax3.set_title(\"äº¤æ˜“æ¯”ä¾‹åœ“é¤…åœ–\")\n",
        "\n",
        "    return \"âœ… å·²ç”Ÿæˆäº¤æ˜“çµ±è¨ˆåœ–è¡¨ï¼\", fig1, fig2, fig3\n",
        "\n",
        "# -------------------------\n",
        "# DataFrame åˆå§‹åŒ–\n",
        "# -------------------------\n",
        "def read_df(ws, header):\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame(columns=header)\n",
        "    df = df.fillna(\"\")\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    return df[header]\n",
        "\n",
        "def write_df(ws, df, header):\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    df_out = df.copy()\n",
        "    for c in header:\n",
        "        if c not in df_out.columns:\n",
        "            df_out[c] = \"\"\n",
        "    df_out = df_out[header]\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out.values.tolist())\n",
        "\n",
        "clips_df = read_df(ws_clips, CLIPS_HEADER)\n",
        "ptt_posts_df = read_df(ws_ptt_posts, PTT_HEADER)\n",
        "terms_df = read_df(ws_ptt_terms, TERMS_HEADER)\n",
        "\n",
        "# -------------------------\n",
        "# æ™‚é–“å‡½æ•¸\n",
        "# -------------------------\n",
        "def tznow():\n",
        "    return datetime.now(gettz(\"Asia/Taipei\")).isoformat()\n",
        "\n",
        "# -------------------------\n",
        "# è‡ªè¨‚ URL æŠ“å–\n",
        "# -------------------------\n",
        "def _get_soup(url):\n",
        "    r = requests.get(url, timeout=15, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "    r.raise_for_status()\n",
        "    return BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "def crawl(url, selector, mode, limit=20):\n",
        "    try:\n",
        "        soup = _get_soup(url)\n",
        "        elements = soup.select(selector)\n",
        "        rows = []\n",
        "        for i, el in enumerate(elements):\n",
        "            if i >= limit:\n",
        "                break\n",
        "            rows.append({\n",
        "                \"clip_id\": str(uuid.uuid4())[:8],\n",
        "                \"text\": el.get_text(strip=True) if mode in [\"text\",\"both\"] else \"\",\n",
        "                \"href\": el.get(\"href\") if mode in [\"href\",\"both\"] else \"\",\n",
        "                \"fetched_at\": tznow()\n",
        "            })\n",
        "        df = pd.DataFrame(rows, columns=CLIPS_HEADER)\n",
        "        if not df.empty:\n",
        "            global clips_df\n",
        "            clips_df = pd.concat([clips_df, df], ignore_index=True)\n",
        "            write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "        return f\"âœ… æŠ“å– {len(rows)} ç­†è³‡æ–™\", df\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}\", pd.DataFrame(columns=CLIPS_HEADER)\n",
        "\n",
        "# -------------------------\n",
        "# PTT ä¿¡ç”¨å¡ç‰ˆçˆ¬èŸ²\n",
        "# -------------------------\n",
        "PTT_COOKIES = {\"over18\": \"1\"}\n",
        "\n",
        "def _parse_nrec(nrec_span):\n",
        "    if not nrec_span:\n",
        "        return 0\n",
        "    txt = nrec_span.get_text(strip=True)\n",
        "    if txt == \"çˆ†\":\n",
        "        return 100\n",
        "    if txt.startswith(\"X\"):\n",
        "        try:\n",
        "            return -int(txt[1:])\n",
        "        except:\n",
        "            return -10\n",
        "    try:\n",
        "        return int(txt)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def crawl_ptt_creditcard(pages=1):\n",
        "    base_url = \"https://www.ptt.cc/bbs/creditcard/index.html\"\n",
        "    all_posts = []\n",
        "\n",
        "    for page in range(pages):\n",
        "        r = requests.get(base_url, cookies=PTT_COOKIES, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        articles = soup.select(\"div.r-ent\")\n",
        "        for a in articles:\n",
        "            title_tag = a.select_one(\".title a\")\n",
        "            if not title_tag:\n",
        "                continue\n",
        "            title = title_tag.text.strip()\n",
        "            link = \"https://www.ptt.cc\" + title_tag[\"href\"]\n",
        "            author = a.select_one(\".author\").text.strip()\n",
        "            date = a.select_one(\".date\").text.strip()\n",
        "            nrec = _parse_nrec(a.select_one(\".nrec span\"))\n",
        "            post_id = link.split(\"/\")[-1].replace(\".html\",\"\")\n",
        "            all_posts.append({\n",
        "                \"post_id\": post_id,\n",
        "                \"title\": title,\n",
        "                \"url\": link,\n",
        "                \"date\": date,\n",
        "                \"author\": author,\n",
        "                \"nrec\": nrec,\n",
        "                \"created_at\": tznow(),\n",
        "                \"fetched_at\": tznow(),\n",
        "                \"content\": \"\"\n",
        "            })\n",
        "        prev_link_tag = soup.select_one(\"a.btn.wide:contains('ä¸Šé ')\")\n",
        "        if prev_link_tag and prev_link_tag.get(\"href\"):\n",
        "            base_url = \"https://www.ptt.cc\" + prev_link_tag.get(\"href\")\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    df_posts = pd.DataFrame(all_posts)\n",
        "    if not df_posts.empty:\n",
        "        global ptt_posts_df\n",
        "        ptt_posts_df = pd.concat([ptt_posts_df, df_posts], ignore_index=True)\n",
        "        write_df(ws_ptt_posts, ptt_posts_df, PTT_HEADER)\n",
        "    return f\"âœ… æˆåŠŸæŠ“å– {len(df_posts)} ç¯‡æ–‡ç« \", df_posts\n",
        "\n",
        "# -------------------------\n",
        "# ç†±è©åˆ†æ\n",
        "# -------------------------\n",
        "STOPWORDS = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "def _tokenize_zh(text):\n",
        "    import re\n",
        "    text = re.sub(r\"[^\\u4e00-\\u9fffA-Za-z0-9]+\", \" \", text)\n",
        "    return [w.strip() for w in jieba.lcut(text) if len(w.strip())>1 and w not in STOPWORDS]\n",
        "\n",
        "def analyze_ptt_texts(topk=10):\n",
        "    global ptt_posts_df, clips_df\n",
        "    # åˆä½µ PTT èˆ‡è‡ªè¨‚ URL æ–‡ç« \n",
        "    df_all = pd.concat([\n",
        "        ptt_posts_df[[\"title\",\"content\"]].rename(columns={\"title\":\"title\",\"content\":\"content\"}),\n",
        "        clips_df[[\"text\"]].rename(columns={\"text\":\"content\"}).assign(title=\"\")\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    if df_all.empty:\n",
        "        return \"âš ï¸ å°šç„¡æ–‡ç« å¯åˆ†æ\", pd.DataFrame(columns=TERMS_HEADER), \"\"\n",
        "\n",
        "    docs = [(r[\"title\"] or \"\") + \" \" + (r[\"content\"] or \"\") for _, r in df_all.iterrows()]\n",
        "\n",
        "    word_counts = Counter()\n",
        "    tokenized_docs = []\n",
        "    for doc in docs:\n",
        "        tokens = _tokenize_zh(doc)\n",
        "        tokenized_docs.append(tokens)\n",
        "        word_counts.update(tokens)\n",
        "\n",
        "    filtered_counts = Counter({w:c for w,c in word_counts.items() if len(w.strip())>1})\n",
        "\n",
        "    docs_str = [\" \".join(tokens) for tokens in tokenized_docs]\n",
        "    vec = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=False)\n",
        "    X = vec.fit_transform(docs_str)\n",
        "    terms = vec.get_feature_names_out()\n",
        "    tfidf_array = X.toarray()\n",
        "    avg_tfidf = defaultdict(float)\n",
        "    for row in tfidf_array:\n",
        "        for i, val in enumerate(row):\n",
        "            avg_tfidf[terms[i]] += val\n",
        "    num_docs = len(docs_str)\n",
        "    for t in avg_tfidf:\n",
        "        avg_tfidf[t] /= num_docs\n",
        "\n",
        "    sorted_terms = sorted(avg_tfidf.items(), key=lambda x: filtered_counts.get(x[0],0), reverse=True)\n",
        "    rows = []\n",
        "    for t, tfidf in sorted_terms[:topk]:\n",
        "        rows.append({\n",
        "            \"term\": t,\n",
        "            \"freq\": filtered_counts.get(t,0),\n",
        "            \"df_count\": 0,\n",
        "            \"tfidf_mean\": round(tfidf,5),\n",
        "            \"examples\": \"\"\n",
        "        })\n",
        "\n",
        "    df_terms = pd.DataFrame(rows, columns=TERMS_HEADER)\n",
        "    global terms_df\n",
        "    terms_df = df_terms\n",
        "    write_df(ws_ptt_terms, terms_df, TERMS_HEADER)\n",
        "    return \"âœ… ç†±è©åˆ†æå®Œæˆ\", df_terms, \"\""
      ],
      "metadata": {
        "id": "oNwDkq3V2Xza"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Gemini API ç”Ÿæˆæ´å¯Ÿæ‘˜è¦\n",
        "# -------------------------\n",
        "import requests\n",
        "import json\n",
        "\n",
        "GEMINI_API_KEY = \"AIzaSyBI639hWVMyMSd4K2dZXVXHftT4sWggNBk\"\n",
        "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
        "\n",
        "def generate_gemini_insights(terms_df):\n",
        "    \"\"\"\n",
        "    ä¾æ“šç†±è©åˆ†æçµæœï¼Œç”Ÿæˆ5å¥æ´å¯Ÿæ‘˜è¦ + ä¸€æ®µ120å­—çµè«–\n",
        "    \"\"\"\n",
        "    prompt = \"æ ¹æ“šä»¥ä¸‹ç†±è©åˆ†æï¼Œç”Ÿæˆ5å¥æ´å¯Ÿæ‘˜è¦ï¼Œä»¥åŠä¸€æ®µç´„120å­—çµè«–ï¼š\\n\\n\"\n",
        "    for _, row in terms_df.iterrows():\n",
        "        prompt += f\"- {row['term']} (å‡ºç¾æ¬¡æ•¸ {row['freq']}, tfidf {row['tfidf_mean']})\\n\"\n",
        "    payload = {\n",
        "        \"model\": GEMINI_MODEL,\n",
        "        \"prompt\": prompt,\n",
        "        \"max_output_tokens\": 400\n",
        "    }\n",
        "    headers = {\"Authorization\": f\"Bearer {GEMINI_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "    try:\n",
        "        r = requests.post(\"https://generativelanguage.googleapis.com/v1beta2/models/gemini-2.5-flash:generateText\",\n",
        "                          headers=headers, data=json.dumps(payload))\n",
        "        r.raise_for_status()\n",
        "        result = r.json()\n",
        "        text = result.get(\"candidates\", [{}])[0].get(\"output\", \"\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ç”Ÿæˆæ´å¯Ÿæ‘˜è¦å¤±æ•—: {e}\"\n",
        "\n",
        "# -------------------------\n",
        "# æ›´æ–°ç†±è©åˆ†æï¼Œä¿ç•™æ­·å²\n",
        "# -------------------------\n",
        "def analyze_ptt_texts(topk=10):\n",
        "    global ptt_posts_df, clips_df, terms_df\n",
        "    # åˆä½µæ–‡ç« \n",
        "    df_all = pd.concat([\n",
        "        ptt_posts_df[[\"title\",\"content\"]].rename(columns={\"title\":\"title\",\"content\":\"content\"}),\n",
        "        clips_df[[\"text\"]].rename(columns={\"text\":\"content\"}).assign(title=\"\")\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    if df_all.empty:\n",
        "        return \"âš ï¸ å°šç„¡æ–‡ç« å¯åˆ†æ\", pd.DataFrame(columns=TERMS_HEADER), \"\"\n",
        "\n",
        "    docs = [(r[\"title\"] or \"\") + \" \" + (r[\"content\"] or \"\") for _, r in df_all.iterrows()]\n",
        "    word_counts = Counter()\n",
        "    tokenized_docs = []\n",
        "    for doc in docs:\n",
        "        tokens = _tokenize_zh(doc)\n",
        "        tokenized_docs.append(tokens)\n",
        "        word_counts.update(tokens)\n",
        "\n",
        "    filtered_counts = Counter({w:c for w,c in word_counts.items() if len(w.strip())>1})\n",
        "    docs_str = [\" \".join(tokens) for tokens in tokenized_docs]\n",
        "    vec = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=False)\n",
        "    X = vec.fit_transform(docs_str)\n",
        "    terms = vec.get_feature_names_out()\n",
        "    tfidf_array = X.toarray()\n",
        "    avg_tfidf = defaultdict(float)\n",
        "    for row in tfidf_array:\n",
        "        for i, val in enumerate(row):\n",
        "            avg_tfidf[terms[i]] += val\n",
        "    num_docs = len(docs_str)\n",
        "    for t in avg_tfidf:\n",
        "        avg_tfidf[t] /= num_docs\n",
        "\n",
        "    sorted_terms = sorted(avg_tfidf.items(), key=lambda x: filtered_counts.get(x[0],0), reverse=True)\n",
        "    rows = []\n",
        "    for t, tfidf in sorted_terms[:topk]:\n",
        "        rows.append({\n",
        "            \"term\": t,\n",
        "            \"freq\": filtered_counts.get(t,0),\n",
        "            \"df_count\": 0,\n",
        "            \"tfidf_mean\": round(tfidf,5),\n",
        "            \"examples\": \"\"\n",
        "        })\n",
        "\n",
        "    new_terms_df = pd.DataFrame(rows, columns=TERMS_HEADER)\n",
        "\n",
        "    # -------------------------\n",
        "    # åˆä½µæ­·å²ç†±è©ï¼Œä¿ç•™æ–°è©\n",
        "    # -------------------------\n",
        "    if not terms_df.empty:\n",
        "        combined_terms = pd.concat([terms_df, new_terms_df], ignore_index=True)\n",
        "        combined_terms = combined_terms.groupby(\"term\").agg({\n",
        "            \"freq\": \"sum\",\n",
        "            \"df_count\": \"sum\",\n",
        "            \"tfidf_mean\": \"mean\",\n",
        "            \"examples\": \"first\"\n",
        "        }).reset_index()\n",
        "        terms_df = combined_terms\n",
        "    else:\n",
        "        terms_df = new_terms_df\n",
        "\n",
        "    write_df(ws_ptt_terms, terms_df, TERMS_HEADER)\n",
        "\n",
        "    # -------------------------\n",
        "    # Gemini API ç”Ÿæˆæ´å¯Ÿæ‘˜è¦\n",
        "    # -------------------------\n",
        "    insights_text = generate_gemini_insights(terms_df)\n",
        "\n",
        "    return \"âœ… ç†±è©åˆ†æå®Œæˆ\", terms_df, insights_text"
      ],
      "metadata": {
        "id": "DIZoWprO3Cqd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Gradio UI ä»‹é¢ ---\n",
        "def gradio_interface():\n",
        "    with gr.Blocks(title=\"Gradio éŠ€è¡Œè¨˜å¸³ç³»çµ± (æ•´åˆ AI é¡§å•) + çˆ¬èŸ²èˆ‡ç†±è©åˆ†æ + Gemini æ´å¯Ÿ\") as demo:\n",
        "        user_status = gr.State(current_user)\n",
        "\n",
        "        with gr.Tab(\"ç™»å…¥/è¨»å†Š\"):\n",
        "            with gr.Row():\n",
        "                username_input = gr.Textbox(label=\"å¸³è™Ÿ\")\n",
        "                password_input = gr.Textbox(label=\"å¯†ç¢¼\", type=\"password\")\n",
        "            with gr.Row():\n",
        "                login_btn = gr.Button(\"ç™»å…¥\")\n",
        "                register_btn = gr.Button(\"è¨»å†Š\")\n",
        "            output_login = gr.Textbox(label=\"ç™»å…¥çµæœ\")\n",
        "\n",
        "            login_btn.click(handle_login, inputs=[username_input, password_input], outputs=output_login).then(\n",
        "                lambda: current_user, None, user_status\n",
        "            )\n",
        "            register_btn.click(handle_register, inputs=[username_input, password_input], outputs=output_login)\n",
        "\n",
        "        with gr.Tab(\"ææ¬¾æ©ŸåŠŸèƒ½\"):\n",
        "            balance_btn = gr.Button(\"æŸ¥çœ‹é¤˜é¡\")\n",
        "            income_input = gr.Number(label=\"å­˜æ¬¾é‡‘é¡\")\n",
        "            income_btn = gr.Button(\"æ–°å¢å­˜æ¬¾é‡‘é¡\")\n",
        "            expense_input = gr.Number(label=\"ææ¬¾é‡‘é¡\")\n",
        "            expense_btn = gr.Button(\"æ–°å¢ææ¬¾é‡‘é¡\")\n",
        "\n",
        "            # è½‰å¸³åŠŸèƒ½\n",
        "            target_user_input = gr.Textbox(label=\"è½‰å¸³ç›®æ¨™å¸³è™Ÿ\")\n",
        "            transfer_input = gr.Number(label=\"è½‰å¸³é‡‘é¡\")\n",
        "            transfer_btn = gr.Button(\"è½‰å¸³\")\n",
        "\n",
        "            clear_btn = gr.Button(\"æ¸…é™¤ç´€éŒ„\")\n",
        "            logout_btn = gr.Button(\"ç™»å‡º\")\n",
        "            output = gr.Textbox(label=\"æ“ä½œçµæœ\")\n",
        "\n",
        "            balance_btn.click(handle_balance, outputs=output)\n",
        "            income_btn.click(handle_income, inputs=[income_input], outputs=output)\n",
        "            expense_btn.click(handle_expense, inputs=[expense_input], outputs=output)\n",
        "            transfer_btn.click(handle_transfer, inputs=[target_user_input, transfer_input], outputs=output)\n",
        "            clear_btn.click(handle_clear, outputs=output)\n",
        "            logout_btn.click(handle_logout, outputs=output)\n",
        "\n",
        "        with gr.Tab(\"ææ¬¾æ©Ÿç´€éŒ„\"):\n",
        "          # ğŸ—“ï¸ æ—¥æœŸç¯©é¸\n",
        "          with gr.Row():\n",
        "              start_date_rec = gr.Textbox(label=\"èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)\")\n",
        "              end_date_rec = gr.Textbox(label=\"çµæŸæ—¥æœŸ (YYYY-MM-DD)\")\n",
        "\n",
        "          # åˆ·æ–°ç´€éŒ„æŒ‰éˆ• + è¡¨æ ¼\n",
        "          records_btn = gr.Button(\"åˆ·æ–°ç´€éŒ„\")\n",
        "          records_table = gr.Dataframe(\n",
        "              headers=[\"ä½¿ç”¨è€…åç¨±\", \"æ—¥æœŸ\", \"æ™‚é–“\", \"å­˜æ¬¾\", \"ææ¬¾\", \"è½‰å¸³\", \"é¤˜é¡\"],\n",
        "              label=\"äº¤æ˜“ç´€éŒ„\"\n",
        "          )\n",
        "          records_btn.click(\n",
        "              handle_records_with_date,  # æ–°å¢æ—¥æœŸç¯©é¸å‡½å¼\n",
        "              inputs=[start_date_rec, end_date_rec],\n",
        "              outputs=records_table\n",
        "          )\n",
        "\n",
        "          # åŒ¯å…¥ / åŒ¯å‡ºåŠŸèƒ½\n",
        "          gr.Markdown(\"### ğŸ“‚ åŒ¯å…¥ / åŒ¯å‡ºåŠŸèƒ½\")\n",
        "          with gr.Row():\n",
        "              import_file = gr.File(label=\"ä¸Šå‚³ CSV æª”æ¡ˆ\")\n",
        "              import_btn = gr.Button(\"åŒ¯å…¥ç´€éŒ„\")\n",
        "              export_btn = gr.Button(\"åŒ¯å‡ºç´€éŒ„\")\n",
        "\n",
        "          import_output = gr.Textbox(label=\"åŒ¯å…¥çµæœ\")\n",
        "          export_file = gr.File(label=\"ä¸‹è¼‰æª”æ¡ˆ\", interactive=False)\n",
        "          export_output = gr.Textbox(label=\"åŒ¯å‡ºçµæœ\")\n",
        "\n",
        "          # ç¶å®šäº‹ä»¶\n",
        "          import_btn.click(handle_import_csv, inputs=[import_file], outputs=import_output)\n",
        "          export_btn.click(handle_export_csv, outputs=[export_file, export_output])\n",
        "\n",
        "\n",
        "\n",
        "        # ğŸ“Š è¦–è¦ºåŒ–çµ±è¨ˆï¼ˆå¯ç¯©é¸æ—¥æœŸï¼‰\n",
        "        with gr.Tab(\"ğŸ“ˆ è¦–è¦ºåŒ–çµ±è¨ˆ\"):\n",
        "            gr.Markdown(\"### ğŸ“Š äº¤æ˜“è¦–è¦ºåŒ–ï¼ˆå¯ç¯©é¸æ—¥æœŸï¼‰\")\n",
        "\n",
        "            with gr.Row():\n",
        "                start_date = gr.Textbox(label=\"èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)\", placeholder=\"ä¾‹å¦‚ï¼š2025-10-01\")\n",
        "                end_date = gr.Textbox(label=\"çµæŸæ—¥æœŸ (YYYY-MM-DD)\", placeholder=\"ä¾‹å¦‚ï¼š2025-10-09\")\n",
        "\n",
        "            gen_btn = gr.Button(\"ç”Ÿæˆçµ±è¨ˆåœ–è¡¨\")\n",
        "\n",
        "            output_text = gr.Textbox(label=\"ç³»çµ±è¨Šæ¯\")\n",
        "            balance_plot = gr.Plot(label=\"é¤˜é¡è®ŠåŒ–åœ–\")\n",
        "            trend_plot = gr.Plot(label=\"äº¤æ˜“è¶¨å‹¢åœ–\")\n",
        "            pie_plot = gr.Plot(label=\"äº¤æ˜“æ¯”ä¾‹åœ“é¤…åœ–\")\n",
        "\n",
        "            # å°‡ Seaborn åœ–è¡¨è½‰çµ¦ Gradio\n",
        "            def generate_visualization(start_date, end_date):\n",
        "                msg, fig_balance, fig_trend, fig_pie = handle_visualization_with_date(start_date, end_date)\n",
        "\n",
        "                figs = []\n",
        "                for fig in [fig_balance, fig_trend, fig_pie]:\n",
        "                    if fig is not None:\n",
        "                        fig.canvas.draw()  # ç¢ºä¿åœ–è¡¨æ›´æ–°\n",
        "                        figs.append(fig)\n",
        "                    else:\n",
        "                        figs.append(None)\n",
        "\n",
        "                return [msg] + figs\n",
        "\n",
        "            gen_btn.click(\n",
        "                fn=generate_visualization,\n",
        "                inputs=[start_date, end_date],\n",
        "                outputs=[output_text, balance_plot, trend_plot, pie_plot]\n",
        "            )\n",
        "\n",
        "\n",
        "        with gr.Tab(\"PTT ç†è²¡ç‰ˆæŠ“å–\"):\n",
        "            pages_input = gr.Number(label=\"æŠ“å–é æ•¸\", value=1)\n",
        "            crawl_ptt_btn = gr.Button(\"ğŸ“° é–‹å§‹æŠ“å–\")\n",
        "            crawl_ptt_msg = gr.Markdown()\n",
        "            crawl_ptt_table = gr.Dataframe(headers=[\"title\",\"url\",\"nrec\"])\n",
        "            crawl_ptt_btn.click(\n",
        "                lambda p: (crawl_ptt_creditcard(p)[0], crawl_ptt_creditcard(p)[1][[\"title\",\"url\",\"nrec\"]].head(10)),\n",
        "                inputs=[pages_input],\n",
        "                outputs=[crawl_ptt_msg, crawl_ptt_table]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"è‡ªè¨‚ URL æŠ“å–\"):\n",
        "            url_input = gr.Textbox(label=\"ç›®æ¨™ URL\", placeholder=\"https://example.com\")\n",
        "            selector_input = gr.Textbox(label=\"CSS Selector\", placeholder=\"a.news-item / h2.title / div.card a\")\n",
        "            mode_input = gr.Radio([\"text\",\"href\",\"both\"], value=\"text\", label=\"æ“·å–å…§å®¹\")\n",
        "            limit_input = gr.Number(value=20, precision=0, label=\"æœ€å¤šæ“·å–å¹¾ç­†\")\n",
        "            crawl_url_btn = gr.Button(\"ğŸ•·ï¸ é–‹å§‹æ“·å–\")\n",
        "            crawl_url_msg = gr.Markdown()\n",
        "            crawl_url_table = gr.Dataframe(headers=CLIPS_HEADER)\n",
        "            crawl_url_btn.click(\n",
        "                crawl,\n",
        "                inputs=[url_input, selector_input, mode_input, limit_input],\n",
        "                outputs=[crawl_url_msg, crawl_url_table]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"PTT ç†±è©åˆ†æ + Gemini æ´å¯Ÿ\"):\n",
        "            topk_input = gr.Number(value=10, precision=0, label=\"å–å‰å¹¾å€‹ç†±è©\")\n",
        "            analyze_btn = gr.Button(\"åˆ†ææ–‡ç« \")\n",
        "            analyze_msg = gr.Markdown()\n",
        "            analyze_table = gr.Dataframe(headers=TERMS_HEADER)\n",
        "            insights_md = gr.Markdown(label=\"Gemini æ´å¯Ÿæ‘˜è¦\")\n",
        "\n",
        "\n",
        "            # ç”Ÿæˆæ´å¯Ÿæ‘˜è¦æŒ‰éˆ•\n",
        "            insights_btn = gr.Button(\"ç”Ÿæˆæ´å¯Ÿæ‘˜è¦\")\n",
        "            insights_md = gr.Markdown(label=\"Gemini æ´å¯Ÿæ‘˜è¦\")\n",
        "\n",
        "            # åˆ†ææ–‡ç« æŒ‰éˆ•\n",
        "            analyze_btn.click(\n",
        "                lambda t: analyze_ptt_texts(t),\n",
        "                inputs=[topk_input],\n",
        "                outputs=[analyze_msg, analyze_table, insights_md]\n",
        "            )\n",
        "\n",
        "            # æ´å¯Ÿæ‘˜è¦æŒ‰éˆ•\n",
        "            insights_btn.click(\n",
        "                lambda: generate_gemini_insights(terms_df),\n",
        "                inputs=[],\n",
        "                outputs=[insights_md]\n",
        "            )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# å•Ÿå‹• Gradio æ‡‰ç”¨\n",
        "demo = gradio_interface()\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "LQS1DquW3DEb",
        "outputId": "36d27a42-a7fb-4f74-bbac-ca8a033ee848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a38049c890226ae65b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a38049c890226ae65b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/soupsieve/css_parser.py:876: FutureWarning: The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.\n",
            "  warnings.warn(  # noqa: B028\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.660 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.660 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}